filter(!str_detect(stockNameEng, 'PRF')) %>%
distinct(stockName, .keep_all = TRUE) %>%
distinct(stockNameEng, .keep_all = TRUE)
View(ticker_mod)
write.csv(ticker_mod, 'ti.csv')
ticker %>% filter(str_detect(stockName, 'PRF'))
ticker %>% filter(str_detect(stockNameEng, 'PREF'))
ticker %>% filter(str_detect(stockName, 'PRRF'))
ticker %>% filter(str_detect(stockName, 'PREF'))
ticker %>% filter(str_detect(stockName, 'Pref'))
# 정리
ticker_mod = ticker %>% filter(closePrice != 0) %>%
filter(!str_detect(stockNameEng, 'ADR')) %>%
filter(!str_detect(stockNameEng, 'Fund')) %>%
filter(!str_detect(stockNameEng, 'Acquisition'))  %>%
filter(!str_detect(stockName, 'Pref')) %>%
filter(!str_detect(stockNameEng, 'PRF')) %>%
distinct(stockName, .keep_all = TRUE) %>%
distinct(stockNameEng, .keep_all = TRUE)
write.csv(ticker_mod, 'ticker.csv')
ticker %>% mutate(clean_name = str_remove(stockNameEng, Ⅰ))
ticker %>% mutate(clean_name = str_remove(stockNameEng, 'Ⅰ'))
ticker %>% filter(str_detect(stockNameEng, 'Ⅰ'))
ticker %>% filter(str_detect(stockNameEng, 'ⅠⅠ'))
ticker %>% filter(str_detect(stockNameEng, 'II'))
ticker %>% filter(str_detect(stockNameEng, 'IIticker %>% filter(str_detect(stockNameEng, 'II'))'))
ticker %>% filter(str_detect(stockNameEng, 'III'))
ticker %>% filter(str_detect(stockNameEng, 'IⅤ'))
ticker %>% filter(str_detect(stockNameEng, 'Ⅳ'))
ticker %>% filter(str_detect(stockNameEng, ''))
ticker %>% filter(str_detect(stockNameEng, 'V'))
ticker %>% filter(str_detect(stockNameEng, 'II'))
ticker %>% filter(str_detect(stockNameEng, 'II')) %>% View()
ticker %>% filter(str_detect(stockNameEng, 'VI'))
ticker %>% filter(str_detect(stockNameEng, 'IV'))
ticker %>% filter(str_detect(stockNameEng, 'V'))
ticker %>% filter(str_detect(stockNameEng, 'VI'))
ticker %>% filter(str_detect(stockNameEng, 'VI')) %>% View()
ticker %>% filter(str_detect(stockNameEng, 'V')) %>% View()
ticker %>% filter(str_detect(stockNameEng, ','))
ticker %>% filter(str_detect(stockNameEng, ','))  %>% View()
ticker %>% filter(str_detect(stockNameEng, '.'))  %>% View()
ticker %>% filter(str_detect(stockNameEng, '\\.'))  %>% View()
ticker %>% filter(str_detect(stockNameEng, 'Class A'))
ticker %>% filter(str_detect(stockNameEng, 'Class B'))
ticker %>% filter(str_detect(stockNameEng, 'Class C'))
ticker %>% filter(str_detect(stockNameEng, 'Class D'))
ticker %>% filter(str_detect(stockNameEng, 'Class E'))
ticker %>% filter(str_detect(stockNameEng, 'Class F'))
ticker %>% filter(str_detect(stockNameEng, 'Unit'))
ticker %>% filter(str_detect(stockNameEng, 'Unit')) %>% View()
ticker %>% filter(str_detect(stockNameEng, 'Series A'))
ticker %>% filter(str_detect(stockNameEng, 'Series A'))
ticker %>% filter(str_detect(stockNameEng, 'Series B'))
ticker %>% filter(str_detect(stockNameEng, 'Series C'))
ticker %>% filter(str_detect(stockNameEng, 'Series D'))
ticker %>% filter(str_detect(stockNameEng, 'Series E'))
ticker %>% filter(str_detect(stockNameEng, 'Series F'))
spe_char = c('II', 'III', 'IV', 'V', '\\.', 'Class A', 'Class B', 'Class C', 'Class D', 'Class E',
'Unit', 'Series A', 'Series B', 'Series C', 'Series D', 'Series E')
?str_remove_all
ticker_mod %>% mutate(clean_name = str_replace(clean_name, spe_char))
ticker_mod %>% mutate(clean_name = str_replace(stockNameEng, spe_char))
spe_char
ticker_mod %>% mutate(clean_name = str_replace(stockNameEng, 'II'))
ticker_mod %>% mutate(clean_name = str_remove_all(stockNameEng, 'II'))
ticker_mod %>% mutate(clean_name = str_remove_all(stockNameEng, 'spe_char'))
z = ticker_mod %>% mutate(clean_name = str_remove_all(stockNameEng, 'spe_char'))
View(z)
z = ticker_mod %>% mutate(clean_name = str_remove_all(stockNameEng, spe_char))
View(z)
spe_char
str_c(words, collapse="|")
spe_char = c('II', 'III', 'IV', 'V', '\\.', 'Class A', 'Class B', 'Class C', 'Class D', 'Class E',
'Unit', 'Series A', 'Series B', 'Series C', 'Series D', 'Series E') %>%
str_c(., collapse="|")
spe_char
trimws
z = ticker_mod %>% mutate(clean_name = str_remove_all(stockNameEng, spe_char))
View(z)
z = ticker_mod %>% mutate(clean_name = str_remove_all(stockNameEng, spe_char)) %>% trimws
z = ticker_mod %>% mutate(clean_name = str_remove_all(stockNameEng, spe_char))
spe_char
View(z)
ticker_mod = ticker %>% filter(closePrice != 0) %>%
filter(!str_detect(stockNameEng, 'ADR')) %>%
filter(!str_detect(stockNameEng, 'Fund')) %>%
filter(!str_detect(stockNameEng, 'Acquisition'))  %>%
filter(!str_detect(stockName, 'Pref')) %>%
filter(!str_detect(stockNameEng, 'PRF')) %>%
distinct(stockName, .keep_all = TRUE) %>%
distinct(stockNameEng, .keep_all = TRUE) %>%
mutate(clean_name = str_remove_all(stockNameEng, spe_char)) %>%
distinct(clean_name, .keep_all = TRUE) %>%
z = ticker_mod %>% mutate(clean_name = str_remove_all(stockNameEng, spe_char))
ticker_mod = ticker %>% filter(closePrice != 0) %>%
filter(!str_detect(stockNameEng, 'ADR')) %>%
filter(!str_detect(stockNameEng, 'Fund')) %>%
filter(!str_detect(stockNameEng, 'Acquisition'))  %>%
filter(!str_detect(stockName, 'Pref')) %>%
filter(!str_detect(stockNameEng, 'PRF')) %>%
distinct(stockName, .keep_all = TRUE) %>%
distinct(stockNameEng, .keep_all = TRUE) %>%
mutate(clean_name = str_remove_all(stockNameEng, spe_char)) %>%
distinct(clean_name, .keep_all = TRUE)
View(ticker_mod)
write.csv(ticker, 'ticker.csv')
write.csv(ticker_mod, 'ticker_mod.csv')
ticker_mod = ticker %>% filter(closePrice != 0) %>%
filter(!str_detect(stockNameEng, 'ADR')) %>%
filter(!str_detect(stockNameEng, 'Fund')) %>%
filter(!str_detect(stockNameEng, 'Acquisition'))  %>%
filter(!str_detect(stockName, 'Pref')) %>%
filter(!str_detect(stockNameEng, 'PRF')) %>%
distinct(stockName, .keep_all = TRUE) %>%
distinct(stockNameEng, .keep_all = TRUE)
View(ticker_mod)
library(rvest)
library(httr)
library(dplyr)
library(lubridate)
library(stringr)
library(magrittr)
library(plotly)
url = 'https://www.multpl.com/shiller-pe/table/by-month'
data = GET(url)
data
# Download table
data_table = data %>% read_html() %>% html_table() %>% .[[1]]
View(data_table)
data_table = data_table %>%
mutate(Date = as.Date(Date, format = "%B %d, %Y")) %>%
set_colnames(c('Date', 'Value'))
View(data_table)
Sys.setlocale("LC_ALL", "English")
url = 'https://www.multpl.com/shiller-pe/table/by-month'
data = GET(url)
# Download table
data_table = data %>% read_html() %>% html_table() %>% .[[1]]
data_table = data_table %>%
mutate(Date = as.Date(Date, format = "%B %d, %Y")) %>%
set_colnames(c('Date', 'Value'))
View(data_table)
# Graph
data_table %>%
plot_ly(x = ~Date, y = ~Value) %>%
add_lines() %>%
layout(xaxis = list(title = ''), yaxis = list(title = ''))
View(data_table)
data_table %>%
ggplot(aes(x = Date, y = Value)) +
geom_line() +
theme_bw()
data_table %>%
plot_ly(x = ~Date, y = ~Value) %>%
add_lines() %>%
layout(xaxis = list(title = ''), yaxis = list(title = ''))
highchart(type = 'stock') %>%
hc_add_series(data_table) %>%
hc_scrollbar(enabled = FALSE)
library(highcharter)
install.packages('highcharter')
highchart(type = 'stock') %>%
hc_add_series(data_table) %>%
hc_scrollbar(enabled = TRUE)
library(highcharter)
highchart(type = 'stock') %>%
hc_add_series(data_table) %>%
hc_scrollbar(enabled = TRUE)
View(data_table)
str(data_table)
library(timetk)
data_table = data_table %>%
mutate(Date = as.Date(Date, format = "%B %d, %Y")) %>%
set_colnames(c('Date', 'Value')) %>%
tk_xts()
highchart(type = 'stock') %>%
hc_add_series(data_table) %>%
hc_scrollbar(enabled = TRUE)
head(data_table)
url = 'https://www.starcapital.de/fileadmin/charts/Res_Aktienmarktbewertungen_FundamentalKZ_Tbl.php?lang=en'
data = fromJSON(url)
data = fromJSON(url)
col_name = data$cols$label
data$rows %>% lapply(., data.frame) %>% .$c %>% t() %>% set_colnames(col_name) %>%
data.frame() %>% set_rownames(NULL) %>%
mutate_at(vars(-c('Country')), as.numeric)
data
data$rows
data$rows %>% lapply(., data.frame)
data
data$rows
data$rows %>% data.frame()
data$rows %>% data.frame() %>% read_csv()
data$rows %>% data.frame() %>% set_colnames(col_name)
data$rows %>% data.frame()
z = data$rows %>% data.frame()
View(z)
View(z[[1]][[1]])
data$rows
data$rows %>% unnest()
data$rows %>% as_tibble()
data$rows %>% as_tibble() %>% unmnest()
data$rows %>% as_tibble() %>% unnest()
data$rows %>% as_tibble() %>% do.call(., cbind)
data$rows %>% as_tibble()
data$rows %>% lapply(., data.frame)
data$rows %>% lapply(., data.frame) %>% .$c %>% t() %>% set_colnames(col_name) %>%
data.frame() %>% set_rownames(NULL) %>%
mutate_at(vars(-c('Country')), as.numeric)
global_cape = data$rows %>% lapply(., data.frame) %>% .$c %>% t() %>% set_colnames(col_name) %>%
data.frame() %>% set_rownames(NULL) %>%
mutate_at(vars(-c('Country')), as.numeric)
head(global_cape)
global_cape = data$rows %>% lapply(., data.frame) %>% .$c %>% t() %>% set_colnames(col_name) %>%
data.frame() %>% set_rownames(NULL) %>%
mutate_at(vars(-c('Country')), as.numeric) %>%
arrange(Score)
global_cape
head(global_cape)
library(DT)
global_cape %>% DT
global_cape %>% data.table()
global_cape %>% datatable()
global_cape %>% datatable()
url = 'https://www.investing.com/indices/service/Price?pairid=0&sid=0.6570837692595137&smlID=74&category=Price&download=true&sort_col=&sort_ord=a'
data = GET(url)
View(data)
data
url = 'https://www.investing.com/indices/Service/Price?pairid%5BmmID%5D=103&pairid%5BquoteType%5D=indice&pairid%5BsmlID%5D=74&sid=10846999623cdfae9be94901cbfa73fe&filterParams=&smlID=74'
data = GET(url)
View(data)
data
data %>% read_html()
url = 'https://www.investing.com/indices/service/Price'
url = 'https://www.investing.com/indices/major-indices'
data = GET(url)
data
data %>% read_html()
data %>% read_html() %>% html_table()
data_table = data %>% read_html() %>% html_table()
data_table[[1]]
data_table[[1]] %>% select(Index, Last, `Chg. %`)
data_table[[1]] %>% select(Index, Last, `Chg. %`) %>%
datatable()
url = 'https://tvc4.forexpros.com/2869e95c1f9634478d6407ea20aa92aa/1612231146/1/1/8/history?symbol=37426&resolution=1&from=1612144753&to=1612231213'
data = fromJSON(url)
View(data)
data %>% data.frame() %>% select(t, c, o, h, l) %>%
mutate_all(as.numeric) %>%
mutate(t = as.POSIXct(t, origin="1970-01-01"))
data
data = data %>% data.frame() %>% select(t, c, o, h, l) %>%
mutate_all(as.numeric) %>%
mutate(t = as.POSIXct(t, origin="1970-01-01"))
d = list(line = list(color = 'blue'))
i = list(line = list(color = 'red'))
data %>%
plot_ly(x = ~t, type="candlestick",
open = ~data_mod$o, close = ~data_mod$c,
high = ~data_mod$h, low = ~data_mod$l,
increasing = i, decreasing = d) %>%
layout(xaxis = list(title = NA),
yaxis = list(title = '(%)'))
data %>%
plot_ly(x = ~t, type="candlestick",
open = ~data$o, close = ~data$c,
high = ~data$h, low = ~data$l,
increasing = i, decreasing = d) %>%
layout(xaxis = list(title = NA),
yaxis = list(title = '(%)'))
setwd("~/R/henry_lab")
library(quantmod)
ticker = c('QQQ', 'SPY', 'EEM', 'XLB', 'IGF', 'PDBC', 'SCHP', 'XLE', 'XLF', 'ACWI', 'TLT')
getSymbols(ticker, from = '2002-12-31')
prices = do.call(cbind,
lapply(symbols, function(x) Ad(get(x)))) %>%
setNames(symbols)
library(quantmod)
library(PerformanceAnalytics)
library(magrittr)
prices = do.call(cbind,
lapply(symbols, function(x) Ad(get(x)))) %>%
setNames(symbols)
prices = do.call(cbind,
lapply(ticker, function(x) Ad(get(x)))) %>%
setNames(symbols)
prices = do.call(cbind,
lapply(ticker, function(x) Ad(get(x)))) %>%
setNames(ticker)
View(prices)
write.csv(data.frame(prices), 'r.csv')
write.csv(data.frame(prices), 'r.csv')
library(httr)
library(rvest)
read_html('www.naver.com')
read_html('https://www.naver.com/')
read_html(GET('https://www.naver.com/'))
a = GET('https://www.naver.com/')
a
library(httr)
library(rvest)
ifelse(dir.exists('data/KOR_fs'), FALSE,
dir.create('data/KOR_fs'))
Sys.setlocale("LC_ALL", "English")
url = paste0('http://comp.fnguide.com/SVO2/ASP/SVD_Finance.asp?pGB=1&gicode=A005930')
data = GET(url,
user_agent('Mozilla/5.0 (Windows NT 10.0; Win64; x64)
AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'))
data = data %>%
read_html() %>%
html_table()
Sys.setlocale("LC_ALL", "Korean")
data
data_IS = data[[1]]
data_BS = data[[3]]
data_CF = data[[5]]
data_IS = data_IS[, 1:(ncol(data_IS)-2)]
data_fs = rbind(data_IS, data_BS, data_CF)
data_fs[, 1] = gsub('계산에 참여한 계정 펼치기',
'', data_fs[, 1])
data_fs = data_fs[!duplicated(data_fs[, 1]), ]
rownames(data_fs) = NULL
rownames(data_fs) = data_fs[, 1]
data_fs[, 1] = NULL
data_fs = data_fs[, substr(colnames(data_fs), 6,7) == '12']
print(head(data_fs))
data_fs = sapply(data_fs, function(x) {
str_replace_all(x, ',', '') %>%
as.numeric()
}) %>%
data.frame(., row.names = rownames(data_fs))
print(head(data_fs))
library(stringr)
data_fs = sapply(data_fs, function(x) {
str_replace_all(x, ',', '') %>%
as.numeric()
}) %>%
data.frame(., row.names = rownames(data_fs))
print(head(data_fs))
library(httr)
library(rvest)
ifelse(dir.exists('data/KOR_fs'), FALSE,
dir.create('data/KOR_fs'))
Sys.setlocale("LC_ALL", "English")
url = paste0('http://comp.fnguide.com/SVO2/ASP/SVD_Finance.asp?pGB=1&gicode=A005930')
data = GET(url,
user_agent('Mozilla/5.0 (Windows NT 10.0; Win64; x64)
AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'))
data = data %>%
read_html() %>%
html_table()
Sys.setlocale("LC_ALL", "Korean")
data
data_IS = data[[1]]
data_BS = data[[3]]
data_CF = data[[5]]
data_IS = data_IS[, 1:(ncol(data_IS)-2)]
'', data_fs[, 1])
data_fs = data_fs[!duplicated(data_fs[, 1]), ]
rownames(data_fs) = NULL
rownames(data_fs) = data_fs[, 1]
data_fs[, 1] = NULL
data_fs = data_fs[, substr(colnames(data_fs), 6,7) == '12']
data_fs = data_fs[!duplicated(data_fs[, 1]), ]
data_fs = rbind(data_IS, data_BS, data_CF)
data_fs[, 1] = gsub('계산에 참여한 계정 펼치기',
'', data_fs[, 1])
data_fs = data_fs[!duplicated(data_fs[, 1]), ]
rownames(data_fs) = NULL
rownames(data_fs) = data_fs[, 1]
data_fs[, 1] = NULL
data_fs = data_fs[, substr(colnames(data_fs), 6,7) == '12']
print(head(data_fs))
library(stringr)
data_fs = sapply(data_fs, function(x) {
str_replace_all(x, ',', '') %>%
as.numeric()
}) %>%
data.frame(., row.names = rownames(data_fs))
print(head(data_fs))
library(httr)
library(rvest)
ifelse(dir.exists('data/KOR_fs'), FALSE,
dir.create('data/KOR_fs'))
Sys.setlocale("LC_ALL", "English")
url = paste0('http://comp.fnguide.com/SVO2/ASP/SVD_Finance.asp?pGB=1&gicode=A005930')
data = GET(url,
user_agent('Mozilla/5.0 (Windows NT 10.0; Win64; x64)
AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'))
data = data %>%
read_html() %>%
html_table()
Sys.setlocale("LC_ALL", "Korean")
data_IS = data[[1]]
data_BS = data[[3]]
data_CF = data[[5]]
data_IS = data_IS[, 1:(ncol(data_IS)-2)]
data_fs = rbind(data_IS, data_BS, data_CF)
data_fs[, 1] = gsub('계산에 참여한 계정 펼치기',
'', data_fs[, 1])
data_fs = data_fs[!duplicated(data_fs[, 1]), ]
rownames(data_fs) = NULL
rownames(data_fs) = data_fs[, 1]
data_fs[, 1] = NULL
data_fs = data_fs[, substr(colnames(data_fs), 6,7) == '12']
print(head(data_fs))
library(stringr)
data_fs = sapply(data_fs, function(x) {
str_replace_all(x, ',', '') %>%
as.numeric()
}) %>%
data.frame(., row.names = rownames(data_fs))
print(head(data_fs))
install.packages('library(fromJson)')
install.packages('fromJson')
install.packages('jsonlite')
library(jsonlite)
## JSON
paste0('https://www.quandl.com/api/v3/datasets/WIKI/FB/data.json?api_key=', key)
key = 'xw3NU3xLUZ7vZgrz5QnG'
## JSON
url_json = paste0('https://www.quandl.com/api/v3/datasets/WIKI/FB/data.json?api_key=', key)
print(url_json)
fromJSON(url_json)
## CSV
url_csv = paste0('https://www.quandl.com/api/v3/datasets/WIKI/FB/data.csv?api_key=', key)
read.csv(url_csv)
data_csv = read.csv(url_csv)
View(data_csv)
library(ggplot2)
head(data_csv)
data_csv %>% ggplot(aes(x = Date, y = Close)
data_csv %>% ggplot(aes(x = Date, y = Close)) +
geom_line()
library(magrittr)
data_csv %>% ggplot(aes(x = Date, y = Close)) +
geom_line()
data_csv %>% ggplot(aes(x = Date, y = Close)) +
geom_line(group = 1)
View(data_csv)
# Quandl Package
install.packages('Quandl')
# Quandl Package
# install.packages('Quandl')
library(Quandl)
data <- Quandl('NSE/OIL', type = "xts"
data <- Quandl('NSE/OIL', type = "xts")
Quandl.api_key(key)
data <- Quandl('NSE/OIL', type = "xts")
data
data <- Quandl('AAPL', type = "xts")
?Quandl
?Quandl.datatable
data <- Quandl('AAPL/WIKI', type = "xts")
data <- Quandl('WIKI/AAPL', type = "xts")
View(data)
## CSV
url_csv = paste0('https://www.quandl.com/api/v3/datasets/WIKI/FB/data.csv?api_key=', key)
data_csv = read.csv(url_csv)
data <- Quandl('WIKI/AAPL', type = "xts")
data = Quandl('WIKI/AAPL', type = "xts")
data_aapl = Quandl('WIKI/AAPL', type = "xts")
head(data_aapl)
data_aapl = Quandl('WIKI/FB', type = "xts")
data_fb = data_aapl
head(data_fb)
Quandl.datatable('SHARADAR/FB', calendardate='2018-12-31', ticker='XOM')
Quandl.datatable('SHARADAR/AAPL', calendardate='2018-12-31', ticker='FB')
Quandl.datatable('SHARADAR/SF1', calendardate='2018-12-31', ticker='FB')
Quandl.api_key(key)
Quandl.datatable('SHARADAR/SF1', calendardate='2020-12-31', ticker='FB')
Quandl.datatable('SHARADAR/SF1', calendardate='2018-12-31', ticker='XOM')
Quandl.datatable('SHARADAR/SF1', calendardate='2018-12-31', ticker='AAPL')
data_aapl_fs = Quandl.datatable('SHARADAR/SF1', calendardate='2018-12-31', ticker='AAPL')
View(data_aapl_fs)
data_aapl_fs = Quandl.datatable('SHARADAR/SF1', calendardate='2018-12-31, 2019-12-31', ticker='AAPL')
View(data_aapl_fs)
data_aapl_fs = Quandl.datatable('SHARADAR/SF1', calendardate='2019-12-31, 2018-12-31', ticker='AAPL')
View(data_aapl_fs)
data_aapl_fs = Quandl.datatable('SHARADAR/SF1', calendardate='2018-12-31, 2017-12-31', ticker='AAPL')
View(data_aapl_fs)
data_aapl_fs = Quandl.datatable('SHARADAR/SF1', calendardate='2018-12-31, 2017-12-31, 2016-12-31', ticker='AAPL')
View(data_aapl_fs)
library(quantmod)
library(PerformanceAnalytics)
library(magrittr)
symbols = c('SPY', # 미국 주식
'IEV', # 유럽 주식
'EWJ', # 일본 주식
'EEM', # 이머징 주식
'TLT', # 미국 장기채
'IEF', # 미국 중기채
'IYR', # 미국 리츠
'RWX', # 글로벌 리츠
'GLD', # 금
'DBC'  # 상품
)
getSymbols(symbols, src = 'yahoo')
getSymbols(symbols, src = 'yahoo', from = '2000-01-01')
prices = do.call(cbind,
lapply(symbols, function(x) Ad(get(x)))) %>%
setNames(symbols)
rets = Return.calculate(prices) %>% na.omit()
View(IYR)
View(rets)
library(readr)
price = read_csv('asset_data.csv')
setwd("C:/Users/doomoolmori/Dropbox/quant_python/data")
price = read_csv('asset_data.csv')
head(price)
View(prices)
